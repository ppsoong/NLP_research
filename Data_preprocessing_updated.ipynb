{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d7a874",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7967c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e5cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"google_scholar.csv\")\n",
    "#load  extra stop words\n",
    "stopwords_df = pd.read_csv('stopwords-en.csv', encoding = \"ISO-8859-1\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd45c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52302, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9217d354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Citaions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Conference Name</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Surveylance: Automatically Detecting Online Su...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Kharraz, W Robertson, E Kirda</td>\n",
       "      <td>39th S&amp;P 2018:\\r\\nSan Francisco, CA, USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>Online surveys are a popular mechanism for per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>EyeTell: Video-Assisted Touchscreen Keystroke ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Y Chen, T Li, R Zhang, Y Zhanga</td>\n",
       "      <td>39th S&amp;P 2018:\\r\\nSan Francisco, CA, USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>Keystroke inference attacks pose an increasing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Understanding Linux Malware</td>\n",
       "      <td>4</td>\n",
       "      <td>E Cozzi, M Graziano, Y Fratantonioa</td>\n",
       "      <td>39th S&amp;P 2018:\\r\\nSan Francisco, CA, USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>For the past two decades, the security communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SoK: Keylogging Side Channels</td>\n",
       "      <td>1</td>\n",
       "      <td>J Monaco</td>\n",
       "      <td>39th S&amp;P 2018:\\r\\nSan Francisco, CA, USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>The first keylogging side channel attack was d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FuturesMEX: Secure, Distributed Futures Market...</td>\n",
       "      <td>2</td>\n",
       "      <td>F Massacci, CN Ngo, J Nie, D Venturia</td>\n",
       "      <td>39th S&amp;P 2018:\\r\\nSan Francisco, CA, USA</td>\n",
       "      <td>2018</td>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>In a Futures-Exchange, such as the Chicago Mer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                              Title  Citaions  \\\n",
       "0      1  Surveylance: Automatically Detecting Online Su...         0   \n",
       "1      2  EyeTell: Video-Assisted Touchscreen Keystroke ...         2   \n",
       "2      3                        Understanding Linux Malware         4   \n",
       "3      4                      SoK: Keylogging Side Channels         1   \n",
       "4      5  FuturesMEX: Secure, Distributed Futures Market...         2   \n",
       "\n",
       "                                 Authors  \\\n",
       "0        A Kharraz, W Robertson, E Kirda   \n",
       "1        Y Chen, T Li, R Zhang, Y Zhanga   \n",
       "2    E Cozzi, M Graziano, Y Fratantonioa   \n",
       "3                               J Monaco   \n",
       "4  F Massacci, CN Ngo, J Nie, D Venturia   \n",
       "\n",
       "                                 Conference  Year Conference Name  \\\n",
       "0  39th S&P 2018:\\r\\nSan Francisco, CA, USA  2018             S&P   \n",
       "1  39th S&P 2018:\\r\\nSan Francisco, CA, USA  2018             S&P   \n",
       "2  39th S&P 2018:\\r\\nSan Francisco, CA, USA  2018             S&P   \n",
       "3  39th S&P 2018:\\r\\nSan Francisco, CA, USA  2018             S&P   \n",
       "4  39th S&P 2018:\\r\\nSan Francisco, CA, USA  2018             S&P   \n",
       "\n",
       "                                            Abstract  \n",
       "0  Online surveys are a popular mechanism for per...  \n",
       "1  Keystroke inference attacks pose an increasing...  \n",
       "2  For the past two decades, the security communi...  \n",
       "3  The first keylogging side channel attack was d...  \n",
       "4  In a Futures-Exchange, such as the Chicago Mer...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "648423fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cookiepoon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#load nltk stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a38e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords = stopwords_df['stop_words'].tolist()\n",
    "extra_stopwords.extend(['any','apply','applying','reapplying','given','papers','paper','about','results','result','real','world','page','article','present','takes','account', 'previous','work','propose','proposes','proposed','simply','simple','demonstrate','demonstrated','demonstrates','realworld','datasets','dataset','provide','important','research','researchers','experiments','experiment','unexpected','discovering','using','recent','collected','solve','columns','existing','traditional','final','consider','presented','provides','automatically','extracting','including','help','helps','explore','illustrate','achieve','better'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "044cd51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566\n"
     ]
    }
   ],
   "source": [
    "# create a whole corpus of stop words\n",
    "total_stop_words = stop_words + extra_stopwords\n",
    "print(len(total_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147b53e",
   "metadata": {},
   "source": [
    "### Generate Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa9b9e",
   "metadata": {},
   "source": [
    "Reference: https://kavita-ganesan.com/how-to-incorporate-phrases-into-word2vec-a-text-mining-approach/#.YGapXkhKhTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "137dc04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrases to count\n",
    "# text cleaning \n",
    "def phrase_to_counts(phrases):\n",
    "    \"\"\" strip any white space and send back a count of 1\"\"\"\n",
    "    clean_phrases = []\n",
    "\n",
    "    for p in phrases:\n",
    "        word = p.strip()\n",
    "\n",
    "        # we only need to count phrases, so ignore unigrams\n",
    "        if len(word) > 1 and ' ' in word:\n",
    "            clean_phrases.append([word, 1])\n",
    "\n",
    "    return clean_phrases\n",
    "\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    \"\"\"remove characters that are not indicators of phrase boundaries\"\"\"\n",
    "    return re.sub(\"([{}@\\\"$%&\\\\\\/*'\\\"]|\\d)\", \"\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82fe3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate candidate phrase\n",
    "def generate_candidate_phrases(text, stopwords):\n",
    "    \"\"\" generate phrases using phrase boundary markers \"\"\"\n",
    "\n",
    "    # generate approximate phrases with punctation\n",
    "    coarse_candidates = text.lower().split()\n",
    "\n",
    "    candidate_phrases = []\n",
    "\n",
    "    for coarse_phrase in coarse_candidates:\n",
    "        #\"\\\\s+\": match sequence of one or more whitespace characters\n",
    "        words = re.split(\"\\\\s+\", coarse_phrase)\n",
    "        previous_stop = False\n",
    "\n",
    "        # examine each word to determine if it is a phrase boundary marker or\n",
    "        # part of a phrase or lone ranger\n",
    "        for w in words:\n",
    "\n",
    "            if w in stopwords and not previous_stop:\n",
    "                # phrase boundary encountered, so put a hard indicator\n",
    "                candidate_phrases.append(\";\")\n",
    "                previous_stop = True\n",
    "            elif w not in stopwords and len(w) > 3:\n",
    "                # keep adding words to list until a phrase boundary is detected\n",
    "                candidate_phrases.append(w.strip())\n",
    "                previous_stop = False\n",
    "\n",
    "    # get a list of candidate phrases without boundary demarcation\n",
    "    phrases = re.split(\";+\", ' '.join(candidate_phrases))\n",
    "\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e85a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tag_phrases(text, stopwords,min_phrase_count=1):\n",
    "    \"\"\"Find top phrases, tag corpora with those top phrases\"\"\"\n",
    "    cleaned_txt = remove_special_characters(text)\n",
    "    normalized_txt = generate_candidate_phrases(cleaned_txt, stopwords)\n",
    "    cleaned_phrases = phrase_to_counts(normalized_txt)\n",
    "    cleaned_phrases.sort(key = lambda x: x[1])\n",
    "    cleaned_phrases = list(filter(lambda x:x[1] >= min_phrase_count, cleaned_phrases))\n",
    "    cleaned_phrases.sort(key = lambda x: x[0])\n",
    "    final_phrases = []\n",
    "    for phrase in cleaned_phrases: \n",
    "      res = phrase[0].replace(\" \", \"_\")  \n",
    "      #print(res) \n",
    "      final_phrases.append(res)\n",
    "      #print(final_phrases)\n",
    "    return final_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d72a8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input as list of strings \n",
    "df_abs = df[['Abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac41fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = df[['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbe9d59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surveylance: Automatically Detecting Online Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EyeTell: Video-Assisted Touchscreen Keystroke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Understanding Linux Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SoK: Keylogging Side Channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FuturesMEX: Secure, Distributed Futures Market...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title\n",
       "0  Surveylance: Automatically Detecting Online Su...\n",
       "1  EyeTell: Video-Assisted Touchscreen Keystroke ...\n",
       "2                        Understanding Linux Malware\n",
       "3                      SoK: Keylogging Side Channels\n",
       "4  FuturesMEX: Secure, Distributed Futures Market..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4a9b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titles(titles):\n",
    "    clean_titles = []\n",
    "    for title in titles: \n",
    "        if \":\" in title:\n",
    "            title_lst = title.split(\":\")\n",
    "            clean_titles.append(title_lst[0])\n",
    "        else: \n",
    "            clean_titles.append(title)\n",
    "    return clean_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1be41767",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_titles['Title'].tolist()\n",
    "short_titles = clean_titles(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "018cacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uni_titles(short_titles):\n",
    "    uni_titles = []\n",
    "    for title in short_titles:\n",
    "        lst = title.split(\" \")\n",
    "        if len(lst) > 1: \n",
    "            uni_title = generate_and_tag_phrases(title, total_stop_words,min_phrase_count=1)\n",
    "            uni_titles.append(uni_title)\n",
    "        else: \n",
    "            uni_titles.append([title])\n",
    "    return uni_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5ad3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_titles = generate_uni_titles(short_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36fef71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52302, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97a39d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('GartnerHypeCycle_EmergingTech.csv', header=0, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1f509ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52332, 3)\n"
     ]
    }
   ],
   "source": [
    "# concatenate labels and abstract\n",
    "abstract_text = df_abs.rename(columns = {'Abstract':'text'})\n",
    "label_text = df_labels.rename(columns = {'Technology': 'text'})\n",
    "df_text = abstract_text.append(label_text)\n",
    "print(df_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7887b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52332\n"
     ]
    }
   ],
   "source": [
    "train_text = df_text['text'].tolist()\n",
    "print(len(train_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b46d8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input train data with duplicate ngrams phrase\n",
    "abs_lab = []\n",
    "for doc in train_text: \n",
    "    doc_phrases = generate_and_tag_phrases(doc, total_stop_words,min_phrase_count=1)\n",
    "    abs_lab.append(doc_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d8873425",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_phrases = abs_lab[:52302]\n",
    "# label_phrases = abs_lab[52302:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eb89f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_phrases = []\n",
    "for lab in label_text['text']:\n",
    "    lab_lst = lab.split(\" \")\n",
    "    lab_string = \"_\".join(lab_lst)\n",
    "    label_phrases.append(lab_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "647daa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate phrases in each document for abstract\n",
    "# set the phrases in the first doc as a reference to remove duplicate values\n",
    "abs_no_dup = []\n",
    "for doc in abs_phrases[:]:\n",
    "    unique_phrases = set(doc)\n",
    "    abs_no_dup.append(list(unique_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54d90188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab_no_dup = pd.DataFrame(abs_no_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a032fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = pd.DataFrame(label_phrases)\n",
    "df_lab.to_csv(\"label_phrases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67653d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survey_scams.</td>\n",
       "      <td>identifying_unique_websites_involved</td>\n",
       "      <td>expose_users</td>\n",
       "      <td>surveylance_works</td>\n",
       "      <td>access_codes</td>\n",
       "      <td>identity_fraud,_deceptive_advertisements,_pote...</td>\n",
       "      <td>survey_scam_detection</td>\n",
       "      <td>services,_mapping</td>\n",
       "      <td>large_number</td>\n",
       "      <td>survey_scam_ecosystem</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soft_keyboard</td>\n",
       "      <td>victims_inputting_process</td>\n",
       "      <td>visually_observe</td>\n",
       "      <td>touchscreen_device</td>\n",
       "      <td>ubiquitous_mobile_devices.</td>\n",
       "      <td>android_devices_confirm</td>\n",
       "      <td>continuous_movements.</td>\n",
       "      <td>prior_work,_eyetell_requires</td>\n",
       "      <td>human_eyes_naturally_focus</td>\n",
       "      <td>high_efficacy</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aspect_causes</td>\n",
       "      <td>time_frame</td>\n",
       "      <td>large-scale_measurement_study_conducted</td>\n",
       "      <td>personal_computers.</td>\n",
       "      <td>embedded_devices</td>\n",
       "      <td>mirai_botnet)_mainly</td>\n",
       "      <td>windows-based_operating_systems._however,</td>\n",
       "      <td>challenges_involved</td>\n",
       "      <td>network-level_behavior,</td>\n",
       "      <td>fighting_malicious_programs</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electromagnetic_spike_emanating</td>\n",
       "      <td>spike,_emitted</td>\n",
       "      <td>idealized_spatial</td>\n",
       "      <td>style._finally,</td>\n",
       "      <td>substantial_measurement_error.</td>\n",
       "      <td>then,_keylogging_attacks</td>\n",
       "      <td>channel_attacks</td>\n",
       "      <td>current_state-of-the-art_keylogging</td>\n",
       "      <td>channel_reveals_physical_locations</td>\n",
       "      <td>channel_attack</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positions,_absence</td>\n",
       "      <td>abort_absence</td>\n",
       "      <td>honest_majority)</td>\n",
       "      <td>exchanges_essentially_non-monotonic_security_b...</td>\n",
       "      <td>desired_currency.</td>\n",
       "      <td>sell_contractual_promises_(futures)</td>\n",
       "      <td>concept_implementation</td>\n",
       "      <td>chicago_mercantile_exchange,_traders</td>\n",
       "      <td>low-frequency_markets</td>\n",
       "      <td>centralized_functionality</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                                     1    \\\n",
       "0                    survey_scams.  identifying_unique_websites_involved   \n",
       "1                    soft_keyboard             victims_inputting_process   \n",
       "2                    aspect_causes                            time_frame   \n",
       "3  electromagnetic_spike_emanating                        spike,_emitted   \n",
       "4               positions,_absence                         abort_absence   \n",
       "\n",
       "                                       2    \\\n",
       "0                             expose_users   \n",
       "1                         visually_observe   \n",
       "2  large-scale_measurement_study_conducted   \n",
       "3                        idealized_spatial   \n",
       "4                         honest_majority)   \n",
       "\n",
       "                                                 3    \\\n",
       "0                                  surveylance_works   \n",
       "1                                 touchscreen_device   \n",
       "2                                personal_computers.   \n",
       "3                                    style._finally,   \n",
       "4  exchanges_essentially_non-monotonic_security_b...   \n",
       "\n",
       "                              4    \\\n",
       "0                    access_codes   \n",
       "1      ubiquitous_mobile_devices.   \n",
       "2                embedded_devices   \n",
       "3  substantial_measurement_error.   \n",
       "4               desired_currency.   \n",
       "\n",
       "                                                 5    \\\n",
       "0  identity_fraud,_deceptive_advertisements,_pote...   \n",
       "1                            android_devices_confirm   \n",
       "2                               mirai_botnet)_mainly   \n",
       "3                           then,_keylogging_attacks   \n",
       "4                sell_contractual_promises_(futures)   \n",
       "\n",
       "                                         6    \\\n",
       "0                      survey_scam_detection   \n",
       "1                      continuous_movements.   \n",
       "2  windows-based_operating_systems._however,   \n",
       "3                            channel_attacks   \n",
       "4                     concept_implementation   \n",
       "\n",
       "                                    7                                   8    \\\n",
       "0                     services,_mapping                        large_number   \n",
       "1          prior_work,_eyetell_requires          human_eyes_naturally_focus   \n",
       "2                   challenges_involved             network-level_behavior,   \n",
       "3   current_state-of-the-art_keylogging  channel_reveals_physical_locations   \n",
       "4  chicago_mercantile_exchange,_traders               low-frequency_markets   \n",
       "\n",
       "                           9    ...   93    94    95    96    97    98    99   \\\n",
       "0        survey_scam_ecosystem  ...  None  None  None  None  None  None  None   \n",
       "1                high_efficacy  ...  None  None  None  None  None  None  None   \n",
       "2  fighting_malicious_programs  ...  None  None  None  None  None  None  None   \n",
       "3               channel_attack  ...  None  None  None  None  None  None  None   \n",
       "4    centralized_functionality  ...  None  None  None  None  None  None  None   \n",
       "\n",
       "    100   101   102  \n",
       "0  None  None  None  \n",
       "1  None  None  None  \n",
       "2  None  None  None  \n",
       "3  None  None  None  \n",
       "4  None  None  None  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ab_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e17f1bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52302, 103)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ab_no_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3a3ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab_no_dup_title = df_ab_no_dup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7138b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab_no_dup_title.insert(0, \"Title\", uni_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "720a082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cookiepoon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_ab_no_dup_title['Title'] = df_ab_no_dup_title['Title'].astype(str).str.replace('\\[|\\]|\\'', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e37e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Surveylance</td>\n",
       "      <td>survey_scams.</td>\n",
       "      <td>identifying_unique_websites_involved</td>\n",
       "      <td>expose_users</td>\n",
       "      <td>surveylance_works</td>\n",
       "      <td>access_codes</td>\n",
       "      <td>identity_fraud,_deceptive_advertisements,_pote...</td>\n",
       "      <td>survey_scam_detection</td>\n",
       "      <td>services,_mapping</td>\n",
       "      <td>large_number</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EyeTell</td>\n",
       "      <td>soft_keyboard</td>\n",
       "      <td>victims_inputting_process</td>\n",
       "      <td>visually_observe</td>\n",
       "      <td>touchscreen_device</td>\n",
       "      <td>ubiquitous_mobile_devices.</td>\n",
       "      <td>android_devices_confirm</td>\n",
       "      <td>continuous_movements.</td>\n",
       "      <td>prior_work,_eyetell_requires</td>\n",
       "      <td>human_eyes_naturally_focus</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>understanding_linux_malware</td>\n",
       "      <td>aspect_causes</td>\n",
       "      <td>time_frame</td>\n",
       "      <td>large-scale_measurement_study_conducted</td>\n",
       "      <td>personal_computers.</td>\n",
       "      <td>embedded_devices</td>\n",
       "      <td>mirai_botnet)_mainly</td>\n",
       "      <td>windows-based_operating_systems._however,</td>\n",
       "      <td>challenges_involved</td>\n",
       "      <td>network-level_behavior,</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SoK</td>\n",
       "      <td>electromagnetic_spike_emanating</td>\n",
       "      <td>spike,_emitted</td>\n",
       "      <td>idealized_spatial</td>\n",
       "      <td>style._finally,</td>\n",
       "      <td>substantial_measurement_error.</td>\n",
       "      <td>then,_keylogging_attacks</td>\n",
       "      <td>channel_attacks</td>\n",
       "      <td>current_state-of-the-art_keylogging</td>\n",
       "      <td>channel_reveals_physical_locations</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FuturesMEX</td>\n",
       "      <td>positions,_absence</td>\n",
       "      <td>abort_absence</td>\n",
       "      <td>honest_majority)</td>\n",
       "      <td>exchanges_essentially_non-monotonic_security_b...</td>\n",
       "      <td>desired_currency.</td>\n",
       "      <td>sell_contractual_promises_(futures)</td>\n",
       "      <td>concept_implementation</td>\n",
       "      <td>chicago_mercantile_exchange,_traders</td>\n",
       "      <td>low-frequency_markets</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title                                0  \\\n",
       "0                  Surveylance                    survey_scams.   \n",
       "1                      EyeTell                    soft_keyboard   \n",
       "2  understanding_linux_malware                    aspect_causes   \n",
       "3                          SoK  electromagnetic_spike_emanating   \n",
       "4                   FuturesMEX               positions,_absence   \n",
       "\n",
       "                                      1  \\\n",
       "0  identifying_unique_websites_involved   \n",
       "1             victims_inputting_process   \n",
       "2                            time_frame   \n",
       "3                        spike,_emitted   \n",
       "4                         abort_absence   \n",
       "\n",
       "                                         2  \\\n",
       "0                             expose_users   \n",
       "1                         visually_observe   \n",
       "2  large-scale_measurement_study_conducted   \n",
       "3                        idealized_spatial   \n",
       "4                         honest_majority)   \n",
       "\n",
       "                                                   3  \\\n",
       "0                                  surveylance_works   \n",
       "1                                 touchscreen_device   \n",
       "2                                personal_computers.   \n",
       "3                                    style._finally,   \n",
       "4  exchanges_essentially_non-monotonic_security_b...   \n",
       "\n",
       "                                4  \\\n",
       "0                    access_codes   \n",
       "1      ubiquitous_mobile_devices.   \n",
       "2                embedded_devices   \n",
       "3  substantial_measurement_error.   \n",
       "4               desired_currency.   \n",
       "\n",
       "                                                   5  \\\n",
       "0  identity_fraud,_deceptive_advertisements,_pote...   \n",
       "1                            android_devices_confirm   \n",
       "2                               mirai_botnet)_mainly   \n",
       "3                           then,_keylogging_attacks   \n",
       "4                sell_contractual_promises_(futures)   \n",
       "\n",
       "                                           6  \\\n",
       "0                      survey_scam_detection   \n",
       "1                      continuous_movements.   \n",
       "2  windows-based_operating_systems._however,   \n",
       "3                            channel_attacks   \n",
       "4                     concept_implementation   \n",
       "\n",
       "                                      7                                   8  \\\n",
       "0                     services,_mapping                        large_number   \n",
       "1          prior_work,_eyetell_requires          human_eyes_naturally_focus   \n",
       "2                   challenges_involved             network-level_behavior,   \n",
       "3   current_state-of-the-art_keylogging  channel_reveals_physical_locations   \n",
       "4  chicago_mercantile_exchange,_traders               low-frequency_markets   \n",
       "\n",
       "   ...    93    94    95    96    97    98    99   100   101   102  \n",
       "0  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "1  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "2  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "3  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "4  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ab_no_dup_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ce1fb",
   "metadata": {},
   "source": [
    "### Split Longer Phrases with length more than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c03b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_underline(df):\n",
    "    corpus_phrases = []\n",
    "    for i in range(df.shape[0]):\n",
    "        doc_phrases = []\n",
    "        for phrase in df.iloc[i]:\n",
    "            if str(phrase) != 'nan':\n",
    "                phrase = str(phrase)\n",
    "                # print(phrase)\n",
    "                res = phrase.replace(\"_\", \" \")\n",
    "                regex = re.compile('[^a-zA-Z]')\n",
    "                res2 = regex.sub(' ', res)\n",
    "                doc_phrases.append(res2)\n",
    "            # else:\n",
    "                # doc_phrases.append(None)\n",
    "        corpus_phrases.append(doc_phrases)\n",
    "    return corpus_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71874a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaN\n",
    "def remove_empty(abstract):\n",
    "    # remove NaN\n",
    "    clean_abstract = []\n",
    "    for doc in abstract:\n",
    "        clean_doc = []\n",
    "        for phrase in doc:\n",
    "            if phrase == \" \":\n",
    "                continue\n",
    "            clean_doc.append(phrase)\n",
    "        clean_abstract.append(clean_doc)\n",
    "    return clean_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3505774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of phrases > 3\n",
    "def detect_longer_phrase(corpus_phrases):\n",
    "    num_length3 = 0\n",
    "    num_length_more = 0\n",
    "    for lst in corpus_phrases: \n",
    "        for phrase in lst:\n",
    "            if len(phrase.split(\" \"))> 3 or len(phrase.split(\",\"))> 3:\n",
    "                num_length_more += 1\n",
    "            elif len(phrase.split(\" \"))> 3 or len(phrase.split(\",\"))> 3: \n",
    "                num_length3 +=1\n",
    "    print(\"There are {} phrases with length three.\".format(num_length3))\n",
    "    print(\"There are {} phrases with lenth more than three.\".format(num_length_more))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c95160f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longer_phrase(corpus_phrases):\n",
    "    longers = []\n",
    "    for lst in corpus_phrases: \n",
    "        for phrase in lst:\n",
    "            if len(phrase.split(\" \"))> 3 or len(phrase.split(\",\"))> 3:\n",
    "                longers.append(phrase)\n",
    "            else:\n",
    "                continue\n",
    "    return longers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d335bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagger to idenitfy structure of phrase\n",
    "def identify_structure(phrases_longer, n):\n",
    "    for phrase in phrases_longer[:n]: \n",
    "        tokens = nltk.word_tokenize(phrase)\n",
    "        print(nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2244281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_longer_phrase(phrases_longer):\n",
    "    # total_clean_phrases = []\n",
    "    candidates = []\n",
    "    tokens = nltk.word_tokenize(phrases_longer)\n",
    "    tag_tokens = nltk.pos_tag(tokens)\n",
    "    for tag_token in tag_tokens:\n",
    "        # at the beginning and it's a verb \n",
    "        if tag_token == tag_tokens[0] and re.match(r'VB', tag_token[1]):\n",
    "            continue\n",
    "        # at the end and it's a verb or an adverb\n",
    "        elif tag_token == tag_tokens[len(tag_tokens)-1] and (re.match(r'VB', tag_token[1]) or re.match(r'RB', tag_token[1])):\n",
    "            continue\n",
    "        candidates.append(tag_token[0])\n",
    "    # for those phrases to keep all words, split 4 word phrase into 2 word phrase \n",
    "    if \",\" not in phrases_longer: \n",
    "        lst = phrases_longer.split(\" \")\n",
    "    else: \n",
    "        lst = phrases_longer.split(\",\")\n",
    "    if len(lst) >3:\n",
    "        tmp1 = \" \".join(lst[:3]).replace('e g', \"\").strip()\n",
    "        tmp2 = \" \".join(lst[3:]).replace('e g', \"\").strip()\n",
    "        return tmp1, tmp2\n",
    "    shorten_tmp = \" \".join(candidates[:]).replace('e g', \"\").strip()\n",
    "    return None, shorten_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "094c2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all_phrase(corpus):\n",
    "    new_corpus = []\n",
    "    for doc in corpus:\n",
    "        new_doc = []\n",
    "        for phrase in doc:\n",
    "            # clean all phrases with length more than three\n",
    "            if len(phrase.split(\" \"))> 3 or len(phrase.split(\",\"))> 3:\n",
    "                first_phrase, sec_phrase = clean_longer_phrase(phrase)\n",
    "                if (not first_phrase) and sec_phrase:\n",
    "                    new_doc.append(sec_phrase)\n",
    "                elif first_phrase and sec_phrase:\n",
    "                    new_doc.append(first_phrase)\n",
    "                    new_doc.append(sec_phrase)\n",
    "            # keep all phrases with length less than three\n",
    "            else:\n",
    "                new_doc.append(phrase)\n",
    "        new_corpus.append(new_doc)\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b40a22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform  phrases back to unigrams\n",
    "def transform_unigrams(corpus):\n",
    "    uni_corpus = []\n",
    "    for doc in corpus: \n",
    "        uni_doc = []\n",
    "        for phrase in doc:\n",
    "            phrase = phrase.strip()\n",
    "            res = phrase.replace(\" \", \"_\")\n",
    "            uni_doc.append(res)\n",
    "        uni_corpus.append(uni_doc)\n",
    "    return uni_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ce200a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_longer_phrases(df):\n",
    "    no_underline_abs_phrases = remove_underline(df)\n",
    "    abs_phrases_ = remove_empty(no_underline_abs_phrases)\n",
    "    detect_longer_phrase(abs_phrases_)\n",
    "    clean_abs_phrases = clean_all_phrase(abs_phrases_)\n",
    "    uni_phrase_corpus = transform_unigrams(clean_abs_phrases)\n",
    "    df_abs_phrases = pd.DataFrame(uni_phrase_corpus)\n",
    "    return df_abs_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fc5cc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 phrases with length three.\n",
      "There are 377694 phrases with lenth more than three.\n"
     ]
    }
   ],
   "source": [
    "df_abs_phrases_notitles = split_longer_phrases(df_ab_no_dup)\n",
    "df_abs_phrases_notitles.to_csv(\"bi_tri_phrases_notitles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "408a7144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 phrases with length three.\n",
      "There are 421148 phrases with lenth more than three.\n"
     ]
    }
   ],
   "source": [
    "df_abs_phrases_titles = split_longer_phrases(df_ab_no_dup_title)\n",
    "df_abs_phrases_titles.to_csv(\"bi_tri_phrases_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64765902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
